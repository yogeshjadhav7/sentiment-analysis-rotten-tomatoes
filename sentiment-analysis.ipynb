{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import all the dependencies\n",
    "import gensim\n",
    "from nltk import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "train_file = \"train.tsv\"\n",
    "test_file = \"test.tsv\"\n",
    "\n",
    "TRAIN_MODEL = True\n",
    "MODEL_NAME = \"trained_model_lstm.hdf5\"\n",
    "FILLER_WORD = \"unk\"\n",
    "\n",
    "def load_data(file, direc=\"\", sep=\"\\t\", header=True):\n",
    "    csv_path = os.path.join(direc, file)\n",
    "    if header:\n",
    "        return pd.read_csv(csv_path, sep=sep, index_col=False)\n",
    "    else:\n",
    "        return pd.read_csv(csv_path, sep=sep, index_col=False, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = load_data(train_file)\n",
    "test_data = load_data(test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase  \\\n",
       "0         1           1  A series of escapades demonstrating the adage ...   \n",
       "1         2           1  A series of escapades demonstrating the adage ...   \n",
       "2         3           1                                           A series   \n",
       "3         4           1                                                  A   \n",
       "4         5           1                                             series   \n",
       "\n",
       "   Sentiment  \n",
       "0          1  \n",
       "1          2  \n",
       "2          2  \n",
       "3          2  \n",
       "4          2  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>156061</td>\n",
       "      <td>8545</td>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>156062</td>\n",
       "      <td>8545</td>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>156063</td>\n",
       "      <td>8545</td>\n",
       "      <td>An</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>156064</td>\n",
       "      <td>8545</td>\n",
       "      <td>intermittently pleasing but mostly routine effort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>156065</td>\n",
       "      <td>8545</td>\n",
       "      <td>intermittently pleasing but mostly routine</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase\n",
       "0    156061        8545  An intermittently pleasing but mostly routine ...\n",
       "1    156062        8545  An intermittently pleasing but mostly routine ...\n",
       "2    156063        8545                                                 An\n",
       "3    156064        8545  intermittently pleasing but mostly routine effort\n",
       "4    156065        8545         intermittently pleasing but mostly routine"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn .model_selection import StratifiedShuffleSplit\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "for train_index, val_index in split.split(train_data, train_data[\"Sentiment\"]):\n",
    "    strat_train_set = train_data.loc[train_index]\n",
    "    strat_val_set = train_data.loc[val_index]\n",
    "    \n",
    "train_data = strat_train_set\n",
    "val_data = strat_val_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "stopword_set = set(stopwords.words('english'))\n",
    "\n",
    "def nlp_clean(data):\n",
    "   new_data = []\n",
    "   for d in data:\n",
    "      new_str = d.lower()\n",
    "      dlist = tokenizer.tokenize(new_str)\n",
    "      dlist = list(set(dlist).difference(stopword_set))\n",
    "      new_data.append(dlist)\n",
    "        \n",
    "   return new_data\n",
    "\n",
    "train_features = nlp_clean(train_data[\"Phrase\"])\n",
    "val_features = nlp_clean(val_data[\"Phrase\"])\n",
    "test_features = nlp_clean(test_data[\"Phrase\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = []\n",
    "\n",
    "for indx in range(len(train_features)):\n",
    "    if len(train_features[indx]) == 0:\n",
    "        train_feature = train_features[indx]\n",
    "        train_feature.append(FILLER_WORD)\n",
    "        train_features[indx] = train_feature\n",
    "    \n",
    "    features.append(train_features[indx])\n",
    "    \n",
    "for indx in range(len(val_features)):\n",
    "    if len(val_features[indx]) == 0:\n",
    "        val_feature = val_features[indx]\n",
    "        val_feature.append(FILLER_WORD)\n",
    "        val_features[indx] = val_feature\n",
    "    \n",
    "    features.append(val_features[indx])\n",
    "        \n",
    "for indx in range(len(test_features)):\n",
    "    if len(test_features[indx]) == 0:\n",
    "        test_feature = test_features[indx]\n",
    "        test_feature.append(FILLER_WORD)\n",
    "        test_features[indx] = test_feature\n",
    "    \n",
    "    features.append(test_features[indx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training word2vec...\n",
      "Word embedding shape: (17631, 300)\n"
     ]
    }
   ],
   "source": [
    "print('\\nTraining word2vec...')\n",
    "word_model = gensim.models.Word2Vec(features, size=300, min_count=1, window=3, iter=100)\n",
    "pretrained_weights = word_model.wv.syn0\n",
    "vocab_size, emdedding_size = pretrained_weights.shape\n",
    "print('Word embedding shape:', pretrained_weights.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2idx(word):\n",
    "    return word_model.wv.vocab[word].index\n",
    "\n",
    "def idx2word(idx):\n",
    "    return word_model.wv.index2word[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_sentences(X):\n",
    "    X_ = []\n",
    "    for n_indx in range(len(X)):\n",
    "        ws_ = []\n",
    "        ws = X[n_indx]\n",
    "        for w_indx in range(len(ws)):\n",
    "            wrd = ws[w_indx]\n",
    "            ws_.append(word2idx(wrd))\n",
    "            \n",
    "        X_.append(ws_)\n",
    "        \n",
    "    return X_\n",
    "\n",
    "train_features = encode_sentences(train_features)\n",
    "val_features = encode_sentences(val_features)\n",
    "test_features = encode_sentences(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_data[\"Sentiment\"].values\n",
    "y_train = np.divide(y_train, 4.0)\n",
    "\n",
    "y_val = val_data[\"Sentiment\"].values\n",
    "y_val = np.divide(y_val, 4.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Padding the data for LSTM...\n",
      "Padding train data...\n",
      "Padding val data...\n",
      "Padding test data...\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Embedding, LSTM, Bidirectional, BatchNormalization\n",
    "from keras.datasets import imdb\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, LambdaCallback\n",
    "from keras.models import load_model\n",
    "\n",
    "MAX_LEN = 100\n",
    "batch_size = 32\n",
    "print(\"Padding the data for LSTM...\")\n",
    "print(\"Padding train data...\")\n",
    "x_train = sequence.pad_sequences(train_features, maxlen=MAX_LEN)\n",
    "print(\"Padding val data...\")\n",
    "x_val = sequence.pad_sequences(val_features, maxlen=MAX_LEN)\n",
    "print(\"Padding test data...\")\n",
    "x_test = sequence.pad_sequences(test_features, maxlen=MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train = x_train[0:10,]\n",
    "#y_train = y_train[0:10,]\n",
    "#x_val = x_val[0:10,]\n",
    "#y_val = y_val[0:10,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "droprate = 0.7\n",
    "\n",
    "try:\n",
    "    model = load_model(MODEL_NAME)\n",
    "    print(\"Loaded saved model: \" + MODEL_NAME)\n",
    "except:\n",
    "    print(\"Creating new model: \" + MODEL_NAME)\n",
    "    model = None\n",
    "\n",
    "if model is None:\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=vocab_size, output_dim=emdedding_size, weights=[pretrained_weights]))\n",
    "    model.add(Bidirectional(LSTM(units=emdedding_size, dropout=droprate, recurrent_dropout=droprate)))\n",
    "    \n",
    "\n",
    "    '''\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(droprate))\n",
    "\n",
    "    model.add(Dense(units=256, activation='elu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(droprate))\n",
    "\n",
    "    model.add(Dense(units=32, activation='elu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(droprate))\n",
    "    '''\n",
    "\n",
    "    model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='mean_squared_error',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "def do_on_epoch_end(epoch, _):\n",
    "    \n",
    "    pred = model.predict(x_val)\n",
    "    actual = y_val.copy()\n",
    "    pred = np.round(pred * 4.0).flatten()\n",
    "    actual = np.round(actual * 4.0).flatten()\n",
    "    acc = sum(pred == actual)/ len(actual)\n",
    "    print(\"Accuracy obtained after epoch: \" + str(acc * 100))\n",
    "    \n",
    "\n",
    "if TRAIN_MODEL:\n",
    "    print('\\nTraining LSTM model...')\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=25,\n",
    "              verbose=0,\n",
    "              validation_data=[x_val, y_val],\n",
    "              callbacks = [ModelCheckpoint(MODEL_NAME, monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='min', period=1),\n",
    "                          LambdaCallback(on_epoch_end=do_on_epoch_end)]\n",
    "             )\n",
    "    \n",
    "print('\\nValidation LSTM model...')\n",
    "saved_model = load_model(MODEL_NAME)\n",
    "score = saved_model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
